---
date: 2024-10-17
title: 2024年你如何使用AI
---

一年多前我简单测试过 ChatGPT，以及基于其上的 New Bing（现在改名叫 Microsoft Copilot）。经过近一年半的发展，大模型又突破了几代。虽然距离真正完全替代某些行业仍然有些遥远，但在各家明争暗卷之下，现在的可用性已经非常高了。

对于某些寻常手段难以触及的那些产品暂且放下不表，今天简单看一下，国内的这几个基于大模型的应用表现如何。

> 声明：本文没有接受任何推广，这些应用也只是我在小米商店随手搜索得到的，也并不能覆盖全部产品。测试内容也非常主观，更多的是从我个人使用的场景上进行一定探索和验证。

本文选定的几款大模型应用分别是：

- 豆包（字节跳动出品）
- 文小言（原文心一言，百度出品）
- 通义（原通义千问，阿里巴巴出品）
- 腾讯元宝（腾讯出品）
- Kimi 智能助手（月之暗面科技出品）
- 智谱清言（智谱华章科技出品）

前四个不必多说，在去年 ChatGPT 刚刚热起来的时候就已经跳出来了，这几个代表性的互联网大公司本身也有这个实力承载相应的研发投入。Kimi 和智谱清言作为新的专注大模型人工智能产品的代表，也一并加入对比。

我会针对下面三个场景各提出一个问题（请求），看这六个产品对应的表现如何。由于完整的回答可能太长，正文中我只会提供我个人对其表现的评价和部分回答的摘要，完整的回答内容会附在文后。

## 信息检索

场景：Top Gear 节目的某一集中提到了捷豹（Jaguar）的经典车型 E-type，我希望知道是哪一集，这样也就省得我专门一集集的翻找了（毕竟22集上百集的内容）。

其实在寻求帮助之前我确实尝试用搜索引擎找过，结果就是给出了明确答案的是某百度知道的问答，但是他答案（第10季第3集）其实是错的。

我给每一个产品的提问内容都是统一的：

> topgear 节目哪一集提到了捷豹的e-type？

这其中，豆包、腾讯元宝和 Kimi 都成功帮我找到了指定的集数（第17集第1集），并简单总结了当期的内容，因为 E-type 50 周年庆，Jeremy 搞了个庆祝活动。

而通义和智谱清言则毫不犹豫的掉进了百度百科的坑，告诉我了错误的答案。

正常来说，一个答案要么正确，要么错误。但是你看前面只出现了 5 个产品，也就是说还有一个在正确或者错误之间选择了或者，这就是百度自家的文小言。

也许是因为知道自家的百度知道并不靠谱，所以给出了一个非常正确但毫无帮助的答案：

> Top Gear节目中提到捷豹E-type的那一集，具体集数可能因节目版本和播出时间的不同而有所差异。根据多个高权威来源的信息，Top Gear曾为捷豹E-type做过一期特集，但具体的集数可能无法直接提供。
>
> 为了找到确切的集数，建议尝试以下方法：
>
> - 访问Top Gear的官方网站或相关汽车媒体的报道，查找关于捷豹E-type特集的详细介绍和播出信息。
> - 在视频分享平台上搜索Top Gear节目中提到捷豹E-type的相关片段，有时视频标题或描述中会包含集数信息。
> - 查阅汽车爱好者论坛或社交媒体上的讨论，可能有其他观众分享了相关集数的信息。
> 
> 请注意，由于节目版本和播出时间的不同，具体的集数可能会有所变化。

似曾相识的结果，因为大部分模型对于作了限制或者无法给出明确答案的内容都会来这么摆烂和稀泥，你不能说他错，但是相对于我之前做过的努力确实没有任何用。

## 语言理解

对于短句的理解我觉得不是什么大问题了，毕竟上面的测试验证了几乎每一个产品都能理解我说的是什么，并且能够检索和总结信息。但是对于一个异常复杂的长难句，能不能正常理解并转译呢。

这个操作我在2009年的时候验证一些在线翻译网站的时候试过，当时几乎得到的都是狗屁不通的结果。现在还是可以拿出来试一试：

> 请把以下句子翻译成英文：
> 
> 怎样用万有引力定律证明文艺复兴时期的二氧化硅在以小说做催化剂的条件下加热可分解为北太平洋暖流和和状语从句，推出核糖核苷酸是马克思理论原理中正弦曲线上一点的结论？

鉴于这段内容其实并没有多长，我就直接把各家的回复原文贴上来，各位可以来评价一下。

这其中豆包、文小言、腾讯元宝和智谱清言都直接给出了自己翻译的结果，整体看下来问题都不大。但是为什么只有这四个呢？

因为通义和 Kimi 都分别提醒我，你这个文本有问题，里面各种概念在逻辑上毫无关联。通义一定程度上提醒了我以后就尝试做了一版翻译，然后分别解释了一下各种各样的地方为什么会冲突。Kimi 则是直接拒绝翻译，直到我说只按字面意思翻译就好，不必纠结逻辑上的对应关系。

通义给出的冲突说明：

> Newton's law of universal gravitation pertains to the gravitational attraction between masses, silica (SiO2) is a chemical compound that does not decompose into ocean currents or grammatical structures, novels are not chemical catalysts, and ribonucleotides (components of RNA) have no direct relationship with Marxist theory or mathematical functions like sine curves.

我不敢直接评价说是不是每个都翻译的非常精确，但对比十五年前的拉垮境地来说，至少在很多概念上的对应上基本都做到了。而我个人更满意的则是他们根据文本能推理出逻辑冲突这个能力，至少在这方面通义和 Kimi 在我这儿多赢了两分。

## 概念表达

我们常见的第三个场景，就是找大模型帮我们润色、扩写或者甚至是创作某些文本。但是单纯的扩写其实并没什么难度，毕竟都是生成式（generative）模型，天生就是吃这口饭的。在这之上我额外加了一些要求：首先生成的结果要是正确的，在概念解释的内容上不能有逻辑性错误；其次就是，要把一些高阶的概念转述成高中生都能懂的语言。

具体的请求内容如下：

> 请用高中生能够理解的语言来描述“Monad 不过是自函子范畴上的幺半群”。

当然了，作为编程圈的一个知名梗，从概念上解释这句话在知乎是有标准答案的，但是如何把概念更进一步地简化解释就是考验这些产品的一个过程。

令人惊喜的是这些产品的解题思路大同小异：先拆解，再总结。基本上就是把其中几个抽象的概念（函子/自函子、幺半群、范畴）类比到更容易理解的概念，然后再组合这些概念去解释 Monad，最后总结这句话所表示的内容。

这其中大部分几乎都会尝试把函子解释成某种盒子、容器或者箱子。而 Kimi 更进一步地把范畴对应成“店铺”，而其之间的函子对应成店铺间/内的通道，用推车小车商场里购物这么一个更综合性的模型来解释，给人看起来确实要更直观一些（当然同样的，对于已经理解了抽象概念的人来说反过来再映射一层反倒是增加了障碍）。

而从另一个表现效果来看，豆包的结果是最口语化而且简洁的，就是似乎在循循善诱地给一个同学讲解一样。这一点在对比AI智能体对话的时候我也有比较深刻的感受：豆包可以通过语音来表演旁白（即对话文字中用括号括起来表现环境或者情绪/动作的部分）所呈现的效果，而通义和腾讯元宝则是直接机械地把旁白读了出来。

## 总结

综合来说，这些产品目前的可用性应付绝大部分生活场景已经很好了。在这之上让我再额外选的话，会比较推荐**豆包**和 **Kimi** 这两个产品。处理专业性问题和信息检索等可以交给 Kimi 去解决，而豆包更丰富的功能可以兼具一部分娱乐属性，可玩性要高很多。

关于这三个问题和这些产品对应的相应结果，可以点击阅读原文访问。